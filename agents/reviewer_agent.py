"""
Reviewer Agent
è´Ÿè´£å®¡æŸ¥å’Œè¯„ä¼°å°è¯´ç« èŠ‚çš„è´¨é‡
"""

import os
import json
from typing import Dict, List, Any, Optional
from dataclasses import dataclass


@dataclass
class ReviewResult:
    """å®¡æŸ¥ç»“æœ"""
    chapter_number: int
    overall_score: float  # 1-10
    plot_coherence: float  # æƒ…èŠ‚è¿è´¯æ€§
    character_consistency: float  # è§’è‰²ä¸€è‡´æ€§
    writing_quality: float  # å†™ä½œè´¨é‡
    engagement: float  # å¸å¼•åŠ›
    technical_accuracy: float  # æŠ€æœ¯å‡†ç¡®æ€§
    strengths: List[str]  # ä¼˜ç‚¹
    weaknesses: List[str]  # ç¼ºç‚¹
    suggestions: List[str]  # ä¿®æ”¹å»ºè®®
    passed: bool  # æ˜¯å¦é€šè¿‡


class ReviewerAgent:
    """
    å®¡æŸ¥ä»£ç†
    
    è¯„ä¼°ç»´åº¦ï¼ˆåŸºäº Anthropic æ–‡ç« ï¼‰ï¼š
    1. æƒ…èŠ‚è¿è´¯æ€§ - æ˜¯å¦ä¸å¤§çº²ä¸€è‡´
    2. è§’è‰²ä¸€è‡´æ€§ - è§’è‰²è¡Œä¸ºæ˜¯å¦ç¬¦åˆè®¾å®š
    3. å†™ä½œè´¨é‡ - æ–‡ç¬”ã€æå†™ã€å¯¹è¯
    4. å¸å¼•åŠ› - æ˜¯å¦å¼•äººå…¥èƒœ
    5. æŠ€æœ¯å‡†ç¡®æ€§ - è¯­æ³•ã€æ ‡ç‚¹ã€æ ¼å¼
    """
    
    def __init__(self, llm_client, project_dir: str):
        self.llm = llm_client
        self.project_dir = project_dir
        self.chapters_dir = os.path.join(project_dir, 'chapters')
    
    def review_chapter(self, chapter_number: int) -> ReviewResult:
        """
        å®¡æŸ¥ç‰¹å®šç« èŠ‚
        
        Args:
            chapter_number: ç« èŠ‚ç¼–å·
        
        Returns:
            å®¡æŸ¥ç»“æœ
        """
        print(f"\nğŸ” Reviewer Agent: æ­£åœ¨å®¡æŸ¥ç¬¬{chapter_number}ç« ")
        
        # 1. åŠ è½½ç« èŠ‚å†…å®¹
        chapter_content = self._load_chapter(chapter_number)
        if not chapter_content:
            print(f"âŒ é”™è¯¯: æ— æ³•åŠ è½½ç¬¬{chapter_number}ç« ")
            return self._create_error_result(chapter_number, "æ— æ³•åŠ è½½ç« èŠ‚")
        
        # 2. åŠ è½½ä¸Šä¸‹æ–‡
        context = self._load_context(chapter_number)
        
        # 3. æ‰§è¡Œå„é¡¹è¯„ä¼°
        print("   æ­£åœ¨è¯„ä¼°æƒ…èŠ‚è¿è´¯æ€§...")
        plot_score = self._evaluate_plot_coherence(chapter_content, context)
        
        print("   æ­£åœ¨è¯„ä¼°è§’è‰²ä¸€è‡´æ€§...")
        character_score = self._evaluate_character_consistency(chapter_content, context)
        
        print("   æ­£åœ¨è¯„ä¼°å†™ä½œè´¨é‡...")
        writing_score = self._evaluate_writing_quality(chapter_content)
        
        print("   æ­£åœ¨è¯„ä¼°å¸å¼•åŠ›...")
        engagement_score = self._evaluate_engagement(chapter_content)
        
        print("   æ­£åœ¨è¯„ä¼°æŠ€æœ¯å‡†ç¡®æ€§...")
        technical_score = self._evaluate_technical_accuracy(chapter_content)
        
        # 4. è®¡ç®—æ€»åˆ†
        overall_score = (plot_score + character_score + writing_score + 
                        engagement_score + technical_score) / 5
        
        # 5. ç”Ÿæˆå»ºè®®
        strengths, weaknesses, suggestions = self._generate_feedback(
            chapter_content, context, 
            plot_score, character_score, writing_score, 
            engagement_score, technical_score
        )
        
        # 6. åˆ¤æ–­æ˜¯å¦é€šè¿‡
        passed = overall_score >= 7.0
        
        result = ReviewResult(
            chapter_number=chapter_number,
            overall_score=overall_score,
            plot_coherence=plot_score,
            character_consistency=character_score,
            writing_quality=writing_score,
            engagement=engagement_score,
            technical_accuracy=technical_score,
            strengths=strengths,
            weaknesses=weaknesses,
            suggestions=suggestions,
            passed=passed
        )
        
        # 7. ä¿å­˜å®¡æŸ¥æŠ¥å‘Š
        self._save_review_report(result)
        
        # 8. è¾“å‡ºç»“æœ
        self._print_review_result(result)
        
        return result
    
    def review_all_chapters(self) -> List[ReviewResult]:
        """å®¡æŸ¥æ‰€æœ‰å·²å®Œæˆçš„ç« èŠ‚"""
        progress = self._load_progress()
        if not progress:
            print("âŒ é”™è¯¯: æœªæ‰¾åˆ°è¿›åº¦æ–‡ä»¶")
            return []
        
        results = []
        for ch in progress['chapters']:
            if ch['status'] == 'completed':
                result = self.review_chapter(ch['chapter_number'])
                results.append(result)
        
        return results
    
    def _load_chapter(self, chapter_number: int) -> Optional[str]:
        """åŠ è½½ç« èŠ‚å†…å®¹"""
        chapter_file = os.path.join(self.chapters_dir, f'chapter-{chapter_number:03d}.md')
        
        if not os.path.exists(chapter_file):
            return None
        
        try:
            with open(chapter_file, 'r', encoding='utf-8') as f:
                return f.read()
        except:
            return None
    
    def _load_context(self, chapter_number: int) -> Dict[str, Any]:
        """åŠ è½½å®¡æŸ¥æ‰€éœ€çš„ä¸Šä¸‹æ–‡"""
        context = {}
        
        # åŠ è½½ç« èŠ‚è§„æ ¼
        chapter_list_file = os.path.join(self.project_dir, 'chapter-list.json')
        if os.path.exists(chapter_list_file):
            with open(chapter_list_file, 'r', encoding='utf-8') as f:
                chapters = json.load(f)
                for ch in chapters:
                    if ch['chapter_number'] == chapter_number:
                        context['chapter_spec'] = ch
                        break
        
        # åŠ è½½è§’è‰²è®¾å®š
        characters_file = os.path.join(self.project_dir, 'characters.json')
        if os.path.exists(characters_file):
            with open(characters_file, 'r', encoding='utf-8') as f:
                context['characters'] = json.load(f)
        
        # åŠ è½½å¤§çº²
        outline_file = os.path.join(self.project_dir, 'outline.md')
        if os.path.exists(outline_file):
            with open(outline_file, 'r', encoding='utf-8') as f:
                context['outline'] = f.read()
        
        # åŠ è½½å‰ä¸€ç« èŠ‚
        if chapter_number > 1:
            prev_file = os.path.join(self.chapters_dir, f'chapter-{chapter_number-1:03d}.md')
            if os.path.exists(prev_file):
                with open(prev_file, 'r', encoding='utf-8') as f:
                    context['previous_chapter'] = f.read()
        
        return context
    
    def _load_progress(self) -> Optional[Dict[str, Any]]:
        """åŠ è½½è¿›åº¦æ–‡ä»¶"""
        progress_file = os.path.join(self.project_dir, 'novel-progress.txt')
        
        if not os.path.exists(progress_file):
            return None
        
        try:
            with open(progress_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            return None
    
    def _evaluate_plot_coherence(self, content: str, context: Dict[str, Any]) -> float:
        """è¯„ä¼°æƒ…èŠ‚è¿è´¯æ€§"""
        chapter_spec = context.get('chapter_spec', {})
        score = 8.0  # åŸºç¡€åˆ†
        
        # æ£€æŸ¥å…³é”®æƒ…èŠ‚ç‚¹
        key_points = chapter_spec.get('key_plot_points', [])
        if key_points:
            covered = 0
            for point in key_points:
                keywords = point.split()[:2]
                if any(kw in content for kw in keywords if len(kw) > 2):
                    covered += 1
            
            coverage = covered / len(key_points)
            if coverage < 0.5:
                score -= 2.0
            elif coverage < 0.8:
                score -= 1.0
            elif coverage >= 0.9:
                score += 0.5
        
        # æ£€æŸ¥ç« èŠ‚æ¦‚è¦åŒ¹é…åº¦ï¼ˆç®€åŒ–ï¼‰
        summary = chapter_spec.get('summary', '')
        if summary:
            summary_keywords = summary.split()[:3]
            matches = sum(1 for kw in summary_keywords if kw in content)
            if matches < len(summary_keywords) * 0.5:
                score -= 0.5
        
        return max(1.0, min(10.0, score))
    
    def _evaluate_character_consistency(self, content: str, context: Dict[str, Any]) -> float:
        """è¯„ä¼°è§’è‰²ä¸€è‡´æ€§"""
        characters = context.get('characters', [])
        chapter_spec = context.get('chapter_spec', {})
        score = 8.0
        
        involved = chapter_spec.get('characters_involved', [])
        
        for char_name in involved:
            char = next((c for c in characters if c['name'] == char_name), None)
            if not char:
                continue
            
            # æ£€æŸ¥è§’è‰²åæ˜¯å¦å‡ºç°
            if char_name not in content:
                score -= 1.0
                continue
            
            # æ£€æŸ¥è§’è‰²ç‰¹å¾è¯ï¼ˆç®€åŒ–ï¼‰
            personality = char.get('personality', '')
            if personality:
                traits = personality.split()[:2]
                if not any(trait in content for trait in traits if len(trait) > 2):
                    score -= 0.3
        
        return max(1.0, min(10.0, score))
    
    def _evaluate_writing_quality(self, content: str) -> float:
        """è¯„ä¼°å†™ä½œè´¨é‡"""
        score = 7.5
        
        # æ£€æŸ¥æ®µè½ç»“æ„
        paragraphs = [p.strip() for p in content.split('\n\n') if p.strip()]
        if len(paragraphs) < 5:
            score -= 1.0
        
        # æ£€æŸ¥å¯¹è¯ï¼ˆç®€åŒ–ï¼‰
        dialogue_count = content.count('"') + content.count('"') + content.count('"')
        if dialogue_count < 10:
            score -= 0.5
        
        # æ£€æŸ¥æå†™ï¼ˆå¯»æ‰¾å½¢å®¹è¯å’Œå‰¯è¯ï¼‰
        descriptive_words = ['ç¾ä¸½', 'é»‘æš—', 'æ˜äº®', 'å¯‚é™', 'å–§é—¹', 'æ¸©æš–', 'å¯’å†·']
        has_description = any(word in content for word in descriptive_words)
        if not has_description:
            score -= 0.5
        
        # æ£€æŸ¥åœºæ™¯è½¬æ¢
        if '---' in content or '***' in content:
            score += 0.3
        
        return max(1.0, min(10.0, score))
    
    def _evaluate_engagement(self, content: str) -> float:
        """è¯„ä¼°å¸å¼•åŠ›"""
        score = 7.0
        
        # æ£€æŸ¥å¼€å¤´å¸å¼•åŠ›
        first_para = content[:200]
        hooks = ['çªç„¶', 'ç„¶è€Œ', 'ä½†æ˜¯', 'æ²¡æƒ³åˆ°', 'æ„å¤–', 'ç¥ç§˜', 'ç§˜å¯†']
        if any(hook in first_para for hook in hooks):
            score += 0.5
        
        # æ£€æŸ¥å†²çªå…ƒç´ 
        conflicts = ['å†²çª', 'çŸ›ç›¾', 'æ–—äº‰', 'å¯¹æŠ—', 'æŒ‘æˆ˜', 'å›°éš¾', 'é—®é¢˜']
        conflict_count = sum(content.count(c) for c in conflicts)
        if conflict_count >= 3:
            score += 0.5
        elif conflict_count == 0:
            score -= 1.0
        
        # æ£€æŸ¥æ‚¬å¿µ
        cliffhangers = ['ï¼Ÿ', '...', 'éš¾é“', 'ç©¶ç«Ÿ', 'åˆ°åº•', 'æ‚¬å¿µ']
        if any(c in content[-200:] for c in cliffhangers):
            score += 0.5
        
        # æ£€æŸ¥æƒ…æ„Ÿè¡¨è¾¾
        emotions = ['æ„Ÿåˆ°', 'è§‰å¾—', 'å¿ƒæƒ…', 'æƒ…ç»ª', 'æ¿€åŠ¨', 'ç´§å¼ ', 'å…´å¥‹']
        if any(e in content for e in emotions):
            score += 0.3
        
        return max(1.0, min(10.0, score))
    
    def _evaluate_technical_accuracy(self, content: str) -> float:
        """è¯„ä¼°æŠ€æœ¯å‡†ç¡®æ€§"""
        score = 9.0
        
        # æ£€æŸ¥æ ‡ç‚¹ä½¿ç”¨
        if content.count('"') % 2 != 0:
            score -= 0.5  # å¼•å·ä¸åŒ¹é…
        
        # æ£€æŸ¥æ®µè½æ ¼å¼
        lines = content.split('\n')
        for line in lines:
            if line.strip() and len(line) > 500:
                score -= 0.2  # æ®µè½è¿‡é•¿
        
        # æ£€æŸ¥é‡å¤ï¼ˆç®€åŒ–ï¼‰
        words = content.split()
        if len(words) > 100:
            unique_words = set(words)
            if len(unique_words) / len(words) < 0.3:
                score -= 0.5  # è¯æ±‡é‡å¤è¿‡å¤š
        
        # æ£€æŸ¥æ ‡é¢˜æ ¼å¼
        if not content.strip().startswith('#'):
            score -= 0.3
        
        return max(1.0, min(10.0, score))
    
    def _generate_feedback(self, content: str, context: Dict[str, Any],
                          plot_score: float, character_score: float,
                          writing_score: float, engagement_score: float,
                          technical_score: float) -> tuple:
        """ç”Ÿæˆåé¦ˆæ„è§"""
        strengths = []
        weaknesses = []
        suggestions = []
        
        # åŸºäºå„é¡¹è¯„åˆ†ç”Ÿæˆåé¦ˆ
        if plot_score >= 8:
            strengths.append("æƒ…èŠ‚è¿è´¯ï¼Œç¬¦åˆå¤§çº²è§„åˆ’")
        elif plot_score < 6:
            weaknesses.append("æƒ…èŠ‚è¿è´¯æ€§æœ‰å¾…æé«˜")
            suggestions.append("ç¡®ä¿æ‰€æœ‰å…³é”®æƒ…èŠ‚ç‚¹éƒ½å¾—åˆ°å±•å¼€")
        
        if character_score >= 8:
            strengths.append("è§’è‰²è¡¨ç°ä¸€è‡´ï¼Œæ€§æ ¼é²œæ˜")
        elif character_score < 6:
            weaknesses.append("è§’è‰²ä¸€è‡´æ€§éœ€è¦åŠ å¼º")
            suggestions.append("æ£€æŸ¥è§’è‰²è¡Œä¸ºæ˜¯å¦ç¬¦åˆå…¶æ€§æ ¼è®¾å®š")
        
        if writing_score >= 8:
            strengths.append("æ–‡ç¬”æµç•…ï¼Œæå†™ç”ŸåŠ¨")
        elif writing_score < 6:
            weaknesses.append("å†™ä½œè´¨é‡éœ€è¦æå‡")
            suggestions.append("å¢åŠ åœºæ™¯æå†™ï¼Œè®©å¯¹è¯æ›´åŠ è‡ªç„¶")
        
        if engagement_score >= 8:
            strengths.append("å†…å®¹å¼•äººå…¥èƒœï¼Œæœ‰é˜…è¯»æ¬²æœ›")
        elif engagement_score < 6:
            weaknesses.append("å¸å¼•åŠ›ä¸è¶³")
            suggestions.append("å¢åŠ å†²çªå’Œæ‚¬å¿µï¼Œæå‡æ•…äº‹å¼ åŠ›")
        
        if technical_score >= 8:
            strengths.append("æ ¼å¼è§„èŒƒï¼Œæ— æ˜æ˜¾é”™è¯¯")
        elif technical_score < 6:
            weaknesses.append("å­˜åœ¨æŠ€æœ¯æ€§é—®é¢˜")
            suggestions.append("æ£€æŸ¥æ ‡ç‚¹ç¬¦å·å’Œæ®µè½æ ¼å¼")
        
        # å­—æ•°æ£€æŸ¥
        chapter_spec = context.get('chapter_spec', {})
        target = chapter_spec.get('word_count_target', 3000)
        actual = len(content)
        if actual < target * 0.8:
            weaknesses.append(f"å­—æ•°ä¸è¶³ï¼ˆ{actual}/{target}ï¼‰")
            suggestions.append(f"æ‰©å……å†…å®¹è‡³ç›®æ ‡å­—æ•°é™„è¿‘")
        elif actual > target * 1.3:
            weaknesses.append(f"å­—æ•°è¶…å‡ºï¼ˆ{actual}/{target}ï¼‰")
            suggestions.append(f"ç²¾ç®€å†…å®¹ï¼Œæ§åˆ¶åœ¨ç›®æ ‡å­—æ•°èŒƒå›´å†…")
        
        return strengths, weaknesses, suggestions
    
    def _save_review_report(self, result: ReviewResult):
        """ä¿å­˜å®¡æŸ¥æŠ¥å‘Š"""
        reviews_dir = os.path.join(self.project_dir, 'reviews')
        os.makedirs(reviews_dir, exist_ok=True)
        
        report_file = os.path.join(reviews_dir, f'review-{result.chapter_number:03d}.md')
        
        report = f"""# ç¬¬{result.chapter_number}ç« å®¡æŸ¥æŠ¥å‘Š

## æ€»ä½“è¯„åˆ†: {result.overall_score:.1f}/10

**ç»“æœ**: {'âœ… é€šè¿‡' if result.passed else 'âŒ éœ€è¦ä¿®æ”¹'}

## è¯¦ç»†è¯„åˆ†

| ç»´åº¦ | åˆ†æ•° |
|------|------|
| æƒ…èŠ‚è¿è´¯æ€§ | {result.plot_coherence:.1f}/10 |
| è§’è‰²ä¸€è‡´æ€§ | {result.character_consistency:.1f}/10 |
| å†™ä½œè´¨é‡ | {result.writing_quality:.1f}/10 |
| å¸å¼•åŠ› | {result.engagement:.1f}/10 |
| æŠ€æœ¯å‡†ç¡®æ€§ | {result.technical_accuracy:.1f}/10 |

## ä¼˜ç‚¹

"""
        for strength in result.strengths:
            report += f"- {strength}\n"
        
        report += "\n## éœ€è¦æ”¹è¿›çš„åœ°æ–¹\n\n"
        for weakness in result.weaknesses:
            report += f"- {weakness}\n"
        
        report += "\n## ä¿®æ”¹å»ºè®®\n\n"
        for suggestion in result.suggestions:
            report += f"- {suggestion}\n"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)
    
    def _print_review_result(self, result: ReviewResult):
        """è¾“å‡ºå®¡æŸ¥ç»“æœ"""
        print(f"\n{'='*60}")
        print(f"ğŸ“Š ç¬¬{result.chapter_number}ç« å®¡æŸ¥ç»“æœ")
        print(f"{'='*60}")
        print(f"æ€»ä½“è¯„åˆ†: {result.overall_score:.1f}/10")
        print(f"ç»“æœ: {'âœ… é€šè¿‡' if result.passed else 'âŒ éœ€è¦ä¿®æ”¹'}")
        print(f"\nè¯¦ç»†è¯„åˆ†:")
        print(f"  æƒ…èŠ‚è¿è´¯æ€§: {result.plot_coherence:.1f}/10")
        print(f"  è§’è‰²ä¸€è‡´æ€§: {result.character_consistency:.1f}/10")
        print(f"  å†™ä½œè´¨é‡: {result.writing_quality:.1f}/10")
        print(f"  å¸å¼•åŠ›: {result.engagement:.1f}/10")
        print(f"  æŠ€æœ¯å‡†ç¡®æ€§: {result.technical_accuracy:.1f}/10")
        
        if result.strengths:
            print(f"\nä¼˜ç‚¹:")
            for s in result.strengths:
                print(f"  âœ“ {s}")
        
        if result.weaknesses:
            print(f"\néœ€è¦æ”¹è¿›:")
            for w in result.weaknesses:
                print(f"  âœ— {w}")
        
        print(f"{'='*60}")
    
    def _create_error_result(self, chapter_number: int, error: str) -> ReviewResult:
        """åˆ›å»ºé”™è¯¯ç»“æœ"""
        return ReviewResult(
            chapter_number=chapter_number,
            overall_score=0,
            plot_coherence=0,
            character_consistency=0,
            writing_quality=0,
            engagement=0,
            technical_accuracy=0,
            strengths=[],
            weaknesses=[error],
            suggestions=["è¯·æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨"],
            passed=False
        )
